{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import packages needed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import einops\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "from torchsummary import summary\n",
    "\n",
    "import torch\n",
    "from torch import nn\n",
    "import torchvision\n",
    "import torch.optim as optim\n",
    "from torchvision.transforms import Compose, Resize, Normalize, RandomHorizontalFlip, RandomCrop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !jupyter nbextension enable --py widgetsnbextension"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Set hyperparameters and specify device."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = \"cuda:0\" if torch.cuda.is_available() else \"cpu\"\n",
    "#print(device)\n",
    "\n",
    "patch_size = 16\n",
    "latent_size = 768\n",
    "n_channels = 3\n",
    "num_heads = 12\n",
    "num_encoders = 12\n",
    "dropout = 0.1\n",
    "num_classes = 10\n",
    "size = 224\n",
    "\n",
    "epochs = 10\n",
    "base_lr = 10e-3\n",
    "weight_decay = 0.03\n",
    "batch_size = 8"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Implementation of input linear projection."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "class InputEmbedding(nn.Module):\n",
    "    def __init__(self, patch_size = patch_size, n_channels = n_channels, device = device, latent_size = latent_size, batch_size = batch_size):\n",
    "        super(InputEmbedding, self).__init__()\n",
    "        self.latent_size = latent_size\n",
    "        self.patch_size = patch_size\n",
    "        self.n_channels = n_channels\n",
    "        self.device = device\n",
    "        self.batch_size = batch_size\n",
    "        self.input_size = self.patch_size*self.patch_size*self.n_channels\n",
    "\n",
    "        #Linear Projection\n",
    "        self.linearProjection = nn.Linear(self.input_size, self.latent_size)\n",
    "\n",
    "        #Class Token\n",
    "                                              # how many in 1 batch? 1Token  dimensions\n",
    "        self.class_token = nn.Parameter(torch.randn(self.batch_size, 1, self.latent_size)).to(self.device)\n",
    "\n",
    "        #Positional Embedding\n",
    "        self.pos_embedding =nn.Parameter(torch.randn(self.batch_size, 1, self.latent_size)).to(self.device)\n",
    "\n",
    "    def forward(self, input_data):\n",
    "        input_data = input_data.to(self.device)\n",
    "\n",
    "        # Patchify Input Image\n",
    "        patches = einops.rearrange(\n",
    "            input_data, \"b c (h h1) (w w1) -> b (h w) (h1 w1 c)\", h1 = self.patch_size, w1 = self.patch_size)\n",
    "        \n",
    "        #print(input_data.size())\n",
    "        #print(patches.size())\n",
    "\n",
    "        linear_projection = self.linearProjection(patches).to(self.device)\n",
    "        b, n, _ = linear_projection.shape\n",
    "\n",
    "        linear_projection = torch.cat((self.class_token, linear_projection), dim = 1) #entlang der 1. Dim hinzugefÃ¼gt\n",
    "        pos_embed = einops.repeat(self.pos_embedding, \"b 1 d -> b m d\", m = n + 1)\n",
    "        \n",
    "        #print(linear_projection.size())\n",
    "        #print(pos_embed.size())\n",
    "\n",
    "        linear_projection += pos_embed\n",
    "\n",
    "        return linear_projection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_input = torch.randn((8,3,224,224))\n",
    "test_class = InputEmbedding().to(device)\n",
    "embed_test = test_class(test_input)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Implement the encoder block."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "class EncoderBlock(nn.Module):\n",
    "    def __init__(self, latent_size = latent_size, num_heads = num_heads, device = device, dropout = dropout):\n",
    "        super(EncoderBlock, self).__init__()\n",
    "\n",
    "        self.latent_size = latent_size\n",
    "        self.num_heads = num_heads\n",
    "        self.device = device\n",
    "        self.dropout = dropout\n",
    "\n",
    "        #Normalization layer\n",
    "        self.norm = nn.LayerNorm(self.latent_size)\n",
    "      \n",
    "        self.multihead = nn.MultiheadAttention(\n",
    "            self.latent_size, self.num_heads, dropout = self.dropout)\n",
    "        \n",
    "        self.enc_MLP = nn.Sequential(\n",
    "            nn.Linear(self.latent_size, self.latent_size*4),\n",
    "            nn.GELU(),\n",
    "            nn.Dropout(self.dropout),\n",
    "            nn.Linear(self.latent_size*4,self.latent_size),\n",
    "            nn.Dropout(self.dropout)\n",
    "        )\n",
    "\n",
    "    def forward(self, embedded_patches):\n",
    "        firstnorm_out = self.norm(embedded_patches)\n",
    "        attention_out = self.multihead(firstnorm_out, firstnorm_out, firstnorm_out)[0]\n",
    "\n",
    "        #first residual connection\n",
    "        first_added = attention_out + embedded_patches\n",
    "\n",
    "        secondnorm_out = self.norm(first_added)\n",
    "        ff_output = self.enc_MLP(secondnorm_out)\n",
    "\n",
    "        output = ff_output + first_added\n",
    "\n",
    "        #print(embedded_patches.size())\n",
    "        #print(output.size())\n",
    "\n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[ 5.2930e-01,  1.8278e-01,  1.6022e+00,  ..., -8.8799e-01,\n",
       "           1.5994e+00, -2.6420e+00],\n",
       "         [ 3.8978e-01,  1.0842e+00,  5.1064e-01,  ..., -3.4221e-01,\n",
       "          -2.1966e-01, -1.1527e+00],\n",
       "         [ 9.1445e-01,  5.4362e-01, -4.8330e-01,  ...,  5.4173e-01,\n",
       "          -6.3929e-01, -1.8867e+00],\n",
       "         ...,\n",
       "         [ 8.4386e-02,  8.7726e-01,  5.5275e-01,  ..., -1.4566e-01,\n",
       "          -8.4374e-01, -2.2914e+00],\n",
       "         [-3.1912e-01, -5.6400e-01,  3.6490e-01,  ...,  2.0771e-01,\n",
       "          -7.0197e-02, -2.5003e+00],\n",
       "         [ 3.0916e-01,  5.8354e-01, -4.3770e-01,  ..., -4.7897e-01,\n",
       "          -4.1521e-01, -1.6929e+00]],\n",
       "\n",
       "        [[-9.4845e-01, -5.4261e-01,  1.1081e+00,  ...,  7.3119e-02,\n",
       "           3.7971e-01,  6.8748e-01],\n",
       "         [-2.1748e+00, -1.2811e+00, -6.4552e-01,  ...,  1.1636e+00,\n",
       "          -2.0746e+00,  4.2849e-01],\n",
       "         [-1.1954e+00,  5.2933e-01, -1.0266e+00,  ...,  1.2726e+00,\n",
       "          -1.8763e+00,  1.7916e+00],\n",
       "         ...,\n",
       "         [-1.1037e+00, -1.3269e-01, -1.1054e+00,  ...,  1.0392e+00,\n",
       "          -2.9314e+00,  8.0072e-01],\n",
       "         [-1.8023e+00, -2.0602e-01, -2.9303e+00,  ...,  1.3194e+00,\n",
       "          -2.5052e+00,  1.0771e+00],\n",
       "         [-3.2174e-01, -1.9911e+00, -1.6170e+00,  ...,  7.0420e-01,\n",
       "          -1.5514e+00,  1.1911e+00]],\n",
       "\n",
       "        [[-2.7217e-01,  2.0570e+00, -1.0971e-01,  ...,  1.2276e+00,\n",
       "          -5.8289e-01, -1.1025e+00],\n",
       "         [-7.3964e-01,  1.1404e+00,  7.5758e-01,  ...,  2.8587e+00,\n",
       "           2.0791e+00, -3.4562e-01],\n",
       "         [-2.8665e-01,  1.1735e+00,  1.0427e+00,  ...,  8.4954e-01,\n",
       "           5.9176e-01, -9.6547e-01],\n",
       "         ...,\n",
       "         [-3.2148e-01,  1.1582e+00,  1.7503e+00,  ...,  1.9650e+00,\n",
       "           1.2372e+00,  1.8690e-01],\n",
       "         [-1.8591e+00,  1.9216e+00,  3.3825e-01,  ...,  1.6371e+00,\n",
       "           1.5481e+00, -1.1299e-01],\n",
       "         [-5.9715e-01,  1.8418e+00,  7.5875e-01,  ...,  2.0498e+00,\n",
       "           1.8115e+00, -2.5100e-02]],\n",
       "\n",
       "        ...,\n",
       "\n",
       "        [[-1.6090e-01, -9.4059e-01, -2.6537e-02,  ..., -1.4098e+00,\n",
       "           4.3296e-01, -1.5578e-01],\n",
       "         [-1.0684e+00, -1.0290e+00, -1.5716e+00,  ..., -3.1198e-01,\n",
       "          -2.5788e-01, -1.6637e+00],\n",
       "         [-2.3698e-01, -3.1856e-01, -5.6163e-01,  ..., -5.7627e-02,\n",
       "           3.1691e-01,  3.9257e-02],\n",
       "         ...,\n",
       "         [-5.5814e-01, -1.5300e+00, -1.2906e+00,  ...,  1.5120e+00,\n",
       "           4.0074e-01, -6.7647e-01],\n",
       "         [-2.2569e-01, -3.9774e-01, -3.1273e-01,  ..., -1.7507e-02,\n",
       "           6.4882e-01,  9.9950e-02],\n",
       "         [ 1.9637e-01, -2.9670e-01, -8.9303e-01,  ..., -4.0963e-01,\n",
       "           5.6430e-01,  8.3339e-01]],\n",
       "\n",
       "        [[-8.2888e-01,  4.2293e-01, -1.2847e+00,  ..., -2.1714e+00,\n",
       "          -1.3675e-01,  1.7651e+00],\n",
       "         [ 6.2030e-01,  1.1489e+00, -1.2431e+00,  ..., -8.5081e-01,\n",
       "           1.6051e+00,  8.6294e-01],\n",
       "         [ 1.2390e+00,  7.7146e-01, -1.3598e-01,  ..., -1.8135e+00,\n",
       "           3.0443e-01,  3.8550e-01],\n",
       "         ...,\n",
       "         [ 2.1753e-01,  4.0725e-01, -6.2751e-01,  ...,  1.3624e-01,\n",
       "          -5.0639e-01,  1.1987e+00],\n",
       "         [ 1.2179e+00,  9.8397e-01, -5.3595e-01,  ..., -1.5621e+00,\n",
       "           5.5464e-01,  9.3276e-01],\n",
       "         [ 1.9876e-01,  8.5356e-01, -1.4201e+00,  ..., -1.6512e+00,\n",
       "           1.1232e+00,  1.8448e+00]],\n",
       "\n",
       "        [[-1.3637e+00,  4.7860e-01, -1.3356e+00,  ...,  5.3205e-01,\n",
       "          -8.4495e-01, -5.6305e-01],\n",
       "         [-6.5461e-01,  1.1217e+00, -2.4527e+00,  ...,  7.3871e-01,\n",
       "           5.2044e-02,  9.9073e-01],\n",
       "         [-3.2400e-01,  1.1498e+00, -2.1156e+00,  ..., -1.2902e+00,\n",
       "          -1.7059e+00,  8.5630e-01],\n",
       "         ...,\n",
       "         [-1.0217e+00,  1.2732e+00, -8.0084e-01,  ..., -3.3642e-01,\n",
       "           2.8440e-02,  1.3406e+00],\n",
       "         [-1.1135e+00,  1.8775e-01, -3.7010e-01,  ..., -2.6077e-03,\n",
       "          -2.2807e+00,  6.6550e-01],\n",
       "         [ 6.1339e-01,  1.5764e+00, -1.9709e+00,  ..., -3.1734e-01,\n",
       "          -1.5122e+00,  4.0224e-01]]], grad_fn=<AddBackward0>)"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_encoder = EncoderBlock().to(device)\n",
    "test_encoder(embed_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Put everything together"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ViT(nn.Module):\n",
    "    def __init__(self, num_encoders=num_encoders, latent_size=latent_size, device=device, num_classes=num_classes, dropout=dropout):\n",
    "        super(ViT, self).__init__()\n",
    "\n",
    "        self.num_encoders = num_encoders\n",
    "        self.latent_size = latent_size\n",
    "        self.device = device\n",
    "        self.num_classes = num_classes\n",
    "        self.dropout = dropout\n",
    "\n",
    "        self.embedding = InputEmbedding()\n",
    "\n",
    "        #Create Stack of Encoders\n",
    "        self.encStack = nn.ModuleList(EncoderBlock() for i in range(self.num_encoders))\n",
    "\n",
    "        self.MLP_head = nn.Sequential(\n",
    "            nn.LayerNorm(self.latent_size),\n",
    "            nn.Linear(self.latent_size, self.latent_size),\n",
    "            nn.Linear(self.latent_size, self.num_classes)\n",
    "        )\n",
    "\n",
    "    def forward(self, test_input):\n",
    "        enc_output = self.embedding(test_input)\n",
    "\n",
    "        for enc_layer in self.encStack:\n",
    "            enc_output = enc_layer(enc_output)\n",
    "\n",
    "        cls_token_embed = enc_output[:, 0]\n",
    "\n",
    "        return self.MLP_head(cls_token_embed)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Test ViT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 0.0624, -0.4705,  0.1533,  0.2916, -0.2076, -0.5198, -0.0619,  0.6661,\n",
      "          0.3178, -0.2557],\n",
      "        [ 0.2574, -0.1355, -0.0260,  0.3431, -0.1586, -0.3548,  0.4580,  0.6288,\n",
      "          0.1264, -0.0667],\n",
      "        [ 0.1556,  0.0872, -0.0180, -0.0119, -0.6361, -0.5154,  0.3149, -0.1762,\n",
      "         -0.0030,  0.4549],\n",
      "        [-0.1011, -0.2652,  0.1837, -0.4612,  0.0316, -0.1454,  0.1524,  0.3946,\n",
      "         -0.2170,  0.7480],\n",
      "        [-0.0068, -0.4800, -0.2421, -0.4517, -0.0962,  0.1658,  0.4228, -0.2135,\n",
      "          0.0531,  0.2083],\n",
      "        [ 0.2849, -0.0120,  0.1465, -0.6187, -0.3015, -0.1000, -0.1478, -0.2426,\n",
      "          0.4067, -0.2238],\n",
      "        [ 0.0549, -0.0337,  0.1273, -0.0380,  0.3378, -0.4076,  0.1464, -0.1642,\n",
      "          0.6452,  0.3868],\n",
      "        [-0.0370,  0.1946, -0.3381, -0.2465, -0.4302, -0.3944, -0.0939, -0.5192,\n",
      "          0.0309,  0.0898]], grad_fn=<AddmmBackward0>)\n",
      "torch.Size([8, 10])\n"
     ]
    }
   ],
   "source": [
    "model = ViT().to(device)\n",
    "vit_output = model(test_input)\n",
    "print(vit_output)\n",
    "print(vit_output.size())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
